# Home_Sales

Use PySpark SQL to create temporary views, partition the data, cache and uncache a temporary table, and verify that the table has been uncached to determine key metrics about home sales data.

First Commit - upload starter code

Second Commit - upload colab code

Third Commit - complete colab code

Fourth Commit - upload Jupyter Notebook code.

Note:  Could not get pyspark to work in Visual Studio
